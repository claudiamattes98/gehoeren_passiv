{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "import re\n",
    "nlp = spacy.load(\"de_dep_news_trf\")\n",
    "import de_dep_news_trf\n",
    "nlp = de_dep_news_trf.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the Excel file into a Pandas dataframe\n",
    "df = pd.read_excel(r'C:\\Users\\matte\\OneDrive\\Masterstudium\\MA gehören\\new data\\code\\gehören500posTI.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding id numbers\n",
    "df['sentence_id'] = df.reset_index().index +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Meta into zeitung und datum\n",
    "df[['Zeitung', 'Rest']] = df['Meta'].str.split('_', n=1, expand=True)\n",
    "\n",
    "# nur das tatsächliche Datum bei 'Datum'\n",
    "df['Datum'] = df['Rest'].str.extract(r'(\\d{4})')\n",
    "\n",
    "df = df.drop(columns=['Rest'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ohnemeta = df.drop(columns=['Meta', 'Zeitung', 'Datum', 'Ressort', 'Mediatype', 'Region'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to normalize text\n",
    "def normalize_text(text):\n",
    "    # remove digits\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    # remove superfluous white spaces\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ohnemeta['text'] = df_ohnemeta.apply(lambda row: ' '.join([str(row[col]) for col in df_ohnemeta.columns]), axis=1)\n",
    "\n",
    "# Normalize the text in the dataframe\n",
    "df_ohnemeta['text'] = df_ohnemeta['text'].apply(normalize_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the text into sentences at the <s>\n",
    "df_ohnemeta['sentences'] = df_ohnemeta['text'].str.split(r'<s>')\n",
    "\n",
    "#explode sentences\n",
    "df_ohnemeta = df_ohnemeta.explode('sentences')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the text into sentences at zeichen\n",
    "df_ohnemeta['punctuation'] = df_ohnemeta['sentences'].str.split(r'[^\\w\\s]')\n",
    "\n",
    "#explode sentences\n",
    "df_ohnemeta = df_ohnemeta.explode('punctuation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the text at the und\n",
    "df_ohnemeta['splitund'] = df_ohnemeta['punctuation'].str.split(r'\\bund\\b')\n",
    "\n",
    "#explode sentences\n",
    "df_ohnemeta = df_ohnemeta.explode('splitund')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ohnemeta['splitund'] = df_ohnemeta['splitund'].apply(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter sentences with gehören\n",
    "target_word = 'gehören'\n",
    "df_filtered = df_ohnemeta[df_ohnemeta['splitund'].apply(lambda x: any([token.lemma_ == target_word for token in x]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unique = df_filtered.drop_duplicates(subset='sentence_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = pd.merge(df[['sentence_id', 'Zeitung', 'Datum', 'Ressort', 'Mediatype', 'Region']], df_unique[['sentence_id', 'text', 'splitund']],  on='sentence_id', how='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract gehören-Formen\n",
    "def extract_gehören(text):\n",
    "    doc = nlp(text)\n",
    "    gehören = [token.text for token in doc if token.lemma_ == 'gehören']\n",
    "    return ', '.join(gehören)\n",
    "\n",
    "# Apply the function to the column and create a new column with the extracted verbs\n",
    "df_merged['gehören'] = df_merged['splitund'].apply(extract_gehören)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract VVPP tagged verbs\n",
    "def extract_vvpp_verbs(text):\n",
    "    doc = nlp(text)\n",
    "    vvpp_verbs = [token.text for token in doc if token.tag_ == 'VVPP' and token.lemma_ != 'gehören']\n",
    "    return ', '.join(vvpp_verbs)\n",
    "\n",
    "# Apply the function to the column and create a new column with the extracted verbs\n",
    "df_merged['VVPP'] = df_merged['splitund'].apply(extract_vvpp_verbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sentence_id Zeitung Datum                     Ressort Mediatype   \n",
      "0              1     APA  2010  inland regional wirtschaft   agentur  \\\n",
      "1              2     APA  2010   politik wirtschaft inland   agentur   \n",
      "2              3     APA  2011              inland politik   agentur   \n",
      "3              4     APA  2011   wirtschaft ausland inland   agentur   \n",
      "4              5     APA  2012                inland sport   agentur   \n",
      "..           ...     ...   ...                         ...       ...   \n",
      "485          496     BVZ  2022                    regional     print   \n",
      "486          497     BVZ  2022                    regional     print   \n",
      "487          498  GRAZER  2022                         NaN     print   \n",
      "488          499  GRAZER  2022                       lokal     print   \n",
      "489          500    NOEN  2022                    regional     print   \n",
      "\n",
      "       Region                                               text   \n",
      "0     agesamt  \" spreche und so tue, als wären Mio. Euro nich...  \\\n",
      "1     agesamt  . <s> (Schluss) <s> ivn/ul <s> APA --/: <s> Ju...   \n",
      "2     agesamt  Wehrdienstverweigerer an die Spitze des österr...   \n",
      "3     agesamt  bei älteren Beschäftigten flacher gestalte: <s...   \n",
      "4     agesamt  Leben' benötigen wir finanzielle Hilfe. <s> Go...   \n",
      "..        ...                                                ...   \n",
      "485      aost  Bürgermeister ließ daher vor Kurzem eine Befra...   \n",
      "486      aost  . <s> „Für solche Art von ‚Spenden‘ haben leid...   \n",
      "487  asuedost  das Tageslicht über das ganze Jahr hinweg.\" <s...   \n",
      "488  asuedost  Folgen, die so ein Leben auch für die Allgemei...   \n",
      "489      aost  bezeichnet haben, für den somit keine Anzeigen...   \n",
      "\n",
      "                                              splitund   gehören        VVPP  \n",
      "0    (Diese, Banker, gehören, in, die, Realität, zu...   gehören      geholt  \n",
      "1    ( , Ferienarbeiter, gehören, nach, dem, Kollek...   gehören  angestellt  \n",
      "2    ( , Aber, dieser, Fehler, gehört, spätestens, ...    gehört  korrigiert  \n",
      "3    ( , Aber, die, Unteren, gehörten, stärker, bet...  gehörten      betont  \n",
      "4           ( , Betreuungskosten, gehören, finanziert)   gehören  finanziert  \n",
      "..                                                 ...       ...         ...  \n",
      "485  ( , dass, der, Verkehr, über, die, Grenze, ein...    gehört  eingedämmt  \n",
      "486  ( , stark, verschmutzte, Gegenstände, gehören,...   gehören    entsorgt  \n",
      "487        ( , gehören, deshalb, besonders, geschützt)   gehören   geschützt  \n",
      "488  ( , Leerstehende, Wohnungen, gehören, geöffnet...   gehören    geöffnet  \n",
      "489  (Alle, Medienplattformen, der, Stadt, gehören,...   gehören     geprüft  \n",
      "\n",
      "[490 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "import openpyxl\n",
    "print(df_merged)\n",
    "df_merged.to_excel('results500leicht.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
