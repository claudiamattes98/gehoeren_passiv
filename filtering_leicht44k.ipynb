{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "import re\n",
    "nlp = spacy.load(\"de_dep_news_trf\")\n",
    "import de_dep_news_trf\n",
    "nlp = de_dep_news_trf.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the Excel file into a Pandas dataframe\n",
    "df = pd.read_excel(r'C:\\Users\\matte\\OneDrive\\Masterstudium\\MA gehören\\new data\\code\\gehören_posTI45k.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding id numbers\n",
    "df['sentence_id'] = df.reset_index().index +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Meta into zeitung und datum\n",
    "df[['Zeitung', 'Rest']] = df['Meta'].str.split('_', n=1, expand=True)\n",
    "\n",
    "# nur das tatsächliche Datum bei 'Datum'\n",
    "df['Datum'] = df['Rest'].str.extract(r'(\\d{4})')\n",
    "\n",
    "df = df.drop(columns=['Rest'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ohnemeta = df.drop(columns=['Meta', 'Zeitung', 'Datum', 'Ressort', 'Mediatype', 'Region'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to normalize text\n",
    "def normalize_text(text):\n",
    "    # remove digits\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    # remove superfluous white spaces\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ohnemeta['text'] = df_ohnemeta.apply(lambda row: ' '.join([str(row[col]) for col in df_ohnemeta.columns]), axis=1)\n",
    "\n",
    "# Normalize the text in the dataframe\n",
    "df_ohnemeta['text'] = df_ohnemeta['text'].apply(normalize_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the text into sentences at the <s>\n",
    "df_ohnemeta['sentences'] = df_ohnemeta['text'].str.split(r'<s>')\n",
    "\n",
    "#explode sentences\n",
    "df_ohnemeta = df_ohnemeta.explode('sentences')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the text into sentences at the <s>\n",
    "df_ohnemeta['punctuation'] = df_ohnemeta['sentences'].str.split(r'[^\\w\\s]')\n",
    "\n",
    "#explode sentences\n",
    "df_ohnemeta = df_ohnemeta.explode('punctuation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the text at the und\n",
    "df_ohnemeta['splitund'] = df_ohnemeta['punctuation'].str.split(r'\\bund\\b')\n",
    "\n",
    "#explode sentences\n",
    "df_ohnemeta = df_ohnemeta.explode('splitund')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ohnemeta['splitund'] = df_ohnemeta['splitund'].apply(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter sentences with gehören\n",
    "target_word = 'gehören'\n",
    "df_filtered = df_ohnemeta[df_ohnemeta['splitund'].apply(lambda x: any([token.lemma_ == target_word for token in x]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unique = df_filtered.drop_duplicates(subset='sentence_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = pd.merge(df[['sentence_id', 'Zeitung', 'Datum', 'Ressort', 'Mediatype', 'Region']], df_unique[['sentence_id', 'text', 'splitund']],  on='sentence_id', how='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract gehören-Formen\n",
    "def extract_gehören(text):\n",
    "    doc = nlp(text)\n",
    "    gehören = [token.text for token in doc if token.lemma_ == 'gehören']\n",
    "    return ', '.join(gehören)\n",
    "\n",
    "# Apply the function to the column and create a new column with the extracted verbs\n",
    "df_merged['gehören'] = df_merged['splitund'].apply(extract_gehören)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract VVPP tagged verbs\n",
    "def extract_vvpp_verbs(text):\n",
    "    doc = nlp(text)\n",
    "    vvpp_verbs = [token.text for token in doc if token.tag_ == 'VVPP' and token.lemma_ != 'gehören']\n",
    "    return ', '.join(vvpp_verbs)\n",
    "\n",
    "# Apply the function to the column and create a new column with the extracted verbs\n",
    "df_merged['VVPP'] = df_merged['splitund'].apply(extract_vvpp_verbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       sentence_id Zeitung Datum    Ressort Mediatype      Region   \n",
      "0                1     APA  2010     inland   agentur     agesamt  \\\n",
      "1                2     APA  2010     inland   agentur     agesamt   \n",
      "2                3     APA  2010      sport   agentur     agesamt   \n",
      "3                5     APA  2010     inland   agentur     agesamt   \n",
      "4                6     APA  2010    ausland   agentur     agesamt   \n",
      "...            ...     ...   ...        ...       ...         ...   \n",
      "43201        45870   WOMAN  2022  allgemein     print  spezifisch   \n",
      "43202        45871   WOMAN  2022  allgemein     print  spezifisch   \n",
      "43203        45872   WOMAN  2022  allgemein     print  spezifisch   \n",
      "43204        45873   WOMAN  2022      lokal     print  spezifisch   \n",
      "43205        45874   WOMAN  2022  allgemein     print  spezifisch   \n",
      "\n",
      "                                         text   \n",
      "0                    gehört ganz abgeschafft   \\\n",
      "1                        gehörte unterbunden    \n",
      "2                         gehört man belohnt    \n",
      "3                         gehöre ausgeweitet    \n",
      "4                           gehört verändert    \n",
      "...                                       ...   \n",
      "43201                  gehört so aufgestellt    \n",
      "43202      gehören in erster Linie beschützt    \n",
      "43203                  gehört wieder gerockt    \n",
      "43204             gehört viel mehr geschmust    \n",
      "43205  gehören doch auch wieder mal gewartet    \n",
      "\n",
      "                                           splitund  gehören         VVPP  \n",
      "0                       (gehört, ganz, abgeschafft)   gehört  abgeschafft  \n",
      "1                            (gehörte, unterbunden)  gehörte  unterbunden  \n",
      "2                            (gehört, man, belohnt)   gehört      belohnt  \n",
      "3                             (gehöre, ausgeweitet)   gehöre  ausgeweitet  \n",
      "4                               (gehört, verändert)   gehört    verändert  \n",
      "...                                             ...      ...          ...  \n",
      "43201                     (gehört, so, aufgestellt)   gehört  aufgestellt  \n",
      "43202       (gehören, in, erster, Linie, beschützt)  gehören    beschützt  \n",
      "43203                     (gehört, wieder, gerockt)   gehört      gerockt  \n",
      "43204               (gehört, viel, mehr, geschmust)   gehört               \n",
      "43205  (gehören, doch, auch, wieder, mal, gewartet)  gehören     gewartet  \n",
      "\n",
      "[43206 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "import openpyxl\n",
    "print(df_merged)\n",
    "df_merged.to_excel('results_posTI45kleicht.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
